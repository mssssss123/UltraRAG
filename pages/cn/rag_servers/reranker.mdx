---
title: "Reranker"
icon: "ranking-star"
---

## 作用

Reranker Server 是 UltraRAG 中用于 对检索结果进行精排的模块。
它接收来自 Retriever Server 的初步检索结果，并基于语义相关性对候选文档进行重新排序，
从而提升检索阶段的精度与最终生成结果的质量。
该模块原生支持多种主流后端包括 [Sentence-Transformers](https://github.com/UKPLab/sentence-transformers)、
[Infinity](https://github.com/michaelfeil/infinity) 以及 [OpenAI](https://platform.openai.com/docs/guides/embeddings)。

## 使用示例

```yaml examples/corpus_rerank.yaml icon="/images/yaml.svg" highlight="5,14,15"
# MCP Server
servers:
  benchmark: servers/benchmark
  retriever: servers/retriever
  reranker: servers/reranker

# MCP Client Pipeline
pipeline:
- benchmark.get_data
- retriever.retriever_init
- retriever.retriever_embed
- retriever.retriever_index
- retriever.retriever_search
- reranker.reranker_init
- reranker.reranker_rerank
```

运行以下命令编译 Pipeline：

```shell
ultrarag build examples/corpus_rerank.yaml
```

修改参数：
```yaml examples/parameters/corpus_search_parameter.yaml icon="/images/yaml.svg"
benchmark:
  benchmark:
    key_map:
      gt_ls: golden_answers
      q_ls: question
    limit: -1
    name: nq
    path: data/sample_nq_10.jsonl
    seed: 42
    shuffle: false
reranker:
  backend: sentence_transformers
  backend_configs:
    infinity:
      bettertransformer: false
      device: cuda
      model_warmup: false
      pooling_method: auto
      trust_remote_code: true
    openai:
      api_key: ''
      base_url: https://api.openai.com/v1
      model_name: text-embedding-3-small
    sentence_transformers:
      device: cuda
      trust_remote_code: true
  batch_size: 16
  gpu_ids: 0
  model_name_or_path: openbmb/MiniCPM-Reranker-Light # [!code --]
  model_name_or_path: BAAI/bge-reranker-large # [!code ++]
  query_instruction: ''
  top_k: 5
retriever:
  backend: sentence_transformers
  backend_configs:
    bm25:
      lang: en
      save_path: index/bm25
    infinity:
      bettertransformer: false
      model_warmup: false
      pooling_method: auto
      trust_remote_code: true
    openai:
      api_key: abc
      base_url: https://api.openai.com/v1
      model_name: text-embedding-3-small
    sentence_transformers:
      sentence_transformers_encode:
        encode_chunk_size: 256
        normalize_embeddings: false
        psg_prompt_name: document
        psg_task: null
        q_prompt_name: query
        q_task: null
      trust_remote_code: true
  batch_size: 16
  collection_name: wiki
  corpus_path: data/corpus_example.jsonl
  embedding_path: embedding/embedding.npy
  gpu_ids: 0,1 # [!code --]
  gpu_ids: 1 # [!code ++]
  index_backend: faiss
  index_backend_configs:
    faiss:
      index_chunk_size: 10000
      index_path: index/index.index
      index_use_gpu: true
    milvus:
      id_field_name: id
      id_max_length: 64
      index_chunk_size: 1000
      index_params:
        index_type: AUTOINDEX
        metric_type: IP
      metric_type: IP
      search_params:
        metric_type: IP
        params: {}
      text_field_name: contents
      text_max_length: 60000
      token: null
      uri: index/milvus_demo.db
      vector_field_name: vector
  is_demo: false
  is_multimodal: false
  model_name_or_path: openbmb/MiniCPM-Embedding-Light # [!code --]
  model_name_or_path: Qwen/Qwen3-Embedding-0.6B # [!code ++]
  overwrite: false
  query_instruction: ''
  top_k: 5
```

运行 Pipeline：
```shell
ultrarag run examples/corpus_rerank.yaml
```