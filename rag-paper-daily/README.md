# ğŸ“š RAG Paper Daily

### ğŸ“… 2025-09-19
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.16112v1">CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion</a></td><td><details><summary>å±•å¼€</summary>Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºCodeRAGçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ä»“åº“çº§ä»£ç è¡¥å…¨æ–¹æ³•ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚ä¸æ°å½“çš„æŸ¥è¯¢æ„å»ºã€å•ä¸€è·¯å¾„çš„ä»£ç æ£€ç´¢ä»¥åŠä»£ç æ£€ç´¢å™¨ä¸å¤§è¯­è¨€æ¨¡å‹ä¹‹é—´çš„ä¸å¯¹é½ã€‚CodeRAGé€šè¿‡æ¦‚ç‡å¼•å¯¼çš„æŸ¥è¯¢æ„å»ºã€å¤šè·¯å¾„ä»£ç æ£€ç´¢å’Œåå¥½å¯¹é½çš„BestFité‡æ’åºç­‰æ ¸å¿ƒç»„ä»¶ï¼Œæå‡äº†æ£€ç´¢å¢å¼ºçš„ä»“åº“çº§ä»£ç è¡¥å…¨çš„æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼ŒCodeRAGåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15883v1">RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning</a></td><td><details><summary>å±•å¼€</summary>Recent retrieval-augmented image captioning methods incorporate external
knowledge to compensate for the limitations in comprehending complex scenes.
However, current approaches face challenges in relation modeling: (1) the
representation of semantic prompts is too coarse-grained to capture
fine-grained relationships; (2) these methods lack explicit modeling of image
objects and their semantic relationships. To address these limitations, we
propose RACap, a relation-aware retrieval-augmented model for image captioning,
which not only mines structured relation semantics from retrieval captions, but
also identifies heterogeneous objects from the image. RACap effectively
retrieves structured relation features that contain heterogeneous visual
information to enhance the semantic consistency and relational expressiveness.
Experimental results show that RACap, with only 10.8M trainable parameters,
achieves superior performance compared to previous lightweight captioning
models.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºRACapçš„å…³ç³»æ„ŸçŸ¥æ£€ç´¢å¢å¼ºå›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡ä»æ£€ç´¢åˆ°çš„æè¿°ä¸­æŒ–æ˜ç»“æ„åŒ–å…³ç³»è¯­ä¹‰å¹¶è¯†åˆ«å›¾åƒä¸­çš„å¼‚æ„å¯¹è±¡ï¼Œä»¥æå‡è¯­ä¹‰ä¸€è‡´æ€§å’Œå…³ç³»è¡¨è¾¾èƒ½åŠ›ï¼Œå®éªŒæ˜¾ç¤ºå…¶åœ¨è½»é‡çº§æ¨¡å‹ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15577v1">Relevance to Utility: Process-Supervised Rewrite for RAG</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation systems often suffer from a gap between
optimizing retrieval relevance and generative utility: retrieved documents may
be topically relevant but still lack the content needed for effective reasoning
during generation. While existing "bridge" modules attempt to rewrite the
retrieved text for better generation, we show how they fail to capture true
document utility. In this work, we propose R2U, with a key distinction of
directly optimizing to maximize the probability of generating a correct answer
through process supervision. As such direct observation is expensive, we also
propose approximating an efficient distillation pipeline by scaling the
supervision from LLMs, which helps the smaller rewriter model generalize
better. We evaluate our method across multiple open-domain question-answering
benchmarks. The empirical results demonstrate consistent improvements over
strong bridging baselines.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºR2Uçš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³RAGç³»ç»Ÿä¸­æ£€ç´¢ç›¸å…³æ€§ä¸ç”Ÿæˆæ•ˆç”¨ä¹‹é—´çš„ä¸ä¸€è‡´é—®é¢˜ã€‚é€šè¿‡ç›´æ¥ä¼˜åŒ–ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡ï¼Œå¹¶åˆ©ç”¨LLMçš„ç›‘ç£ä¿¡å·æ¥é«˜æ•ˆè®­ç»ƒè¾ƒå°çš„é‡å†™æ¨¡å‹ï¼Œè®ºæ–‡åœ¨å¤šä¸ªå¼€æ”¾åŸŸé—®ç­”åŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•çš„æ€§èƒ½ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-18
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.15211v1">What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques</a></td><td><details><summary>å±•å¼€</summary>Slide decks, serving as digital reports that bridge the gap between
presentation slides and written documents, are a prevalent medium for conveying
information in both academic and corporate settings. Their multimodal nature,
combining text, images, and charts, presents challenges for retrieval-augmented
generation systems, where the quality of retrieval directly impacts downstream
performance. Traditional approaches to slide retrieval often involve separate
indexing of modalities, which can increase complexity and lose contextual
information. This paper investigates various methodologies for effective slide
retrieval, including visual late-interaction embedding models like ColPali, the
use of visual rerankers, and hybrid retrieval techniques that combine dense
retrieval with BM25, further enhanced by textual rerankers and fusion methods
like Reciprocal Rank Fusion. A novel Vision-Language Models-based captioning
pipeline is also evaluated, demonstrating significantly reduced embedding
storage requirements compared to visual late-interaction techniques, alongside
comparable retrieval performance. Our analysis extends to the practical aspects
of these methods, evaluating their runtime performance and storage demands
alongside retrieval efficacy, thus offering practical guidance for the
selection and development of efficient and robust slide retrieval systems for
real-world applications.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¹»ç¯ç‰‡ï¼ˆåŒ…å«æ–‡æœ¬ã€å›¾åƒå’Œå›¾è¡¨ï¼‰çš„é«˜æ•ˆæ£€ç´¢æ–¹æ³•ï¼Œæ¢è®¨äº†è§†è§‰å»¶è¿Ÿäº¤äº’åµŒå…¥æ¨¡å‹ã€è§†è§‰é‡æ’åºå™¨ã€æ··åˆæ£€ç´¢æŠ€æœ¯ï¼ˆç»“åˆç¨ å¯†æ£€ç´¢ä¸BM25ï¼‰ç­‰æ–¹æ¡ˆï¼Œå¹¶æå‡ºåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æ ‡é¢˜ç”Ÿæˆæµç¨‹ï¼Œåœ¨ä¿è¯æ£€ç´¢æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½å­˜å‚¨éœ€æ±‚ï¼Œä¸ºRAGç³»ç»Ÿä¸­å¹»ç¯ç‰‡æ£€ç´¢çš„å®é™…åº”ç”¨æä¾›æ•ˆèƒ½è¯„ä¼°ä¸å¼€å‘æŒ‡å¯¼ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15159v1">AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
retrieving relevant documents from external sources to improve factual accuracy
and verifiability. However, this reliance introduces new attack surfaces within
the retrieval pipeline, beyond the LLM itself. While prior RAG attacks have
exposed such vulnerabilities, they largely rely on manipulating user queries,
which is often infeasible in practice due to fixed or protected user inputs.
This narrow focus overlooks a more realistic and stealthy vector: instructional
prompts, which are widely reused, publicly shared, and rarely audited. Their
implicit trust makes them a compelling target for adversaries to manipulate RAG
behavior covertly.
  We introduce a novel attack for Adversarial Instructional Prompt (AIP) that
exploits adversarial instructional prompts to manipulate RAG outputs by subtly
altering retrieval behavior. By shifting the attack surface to the
instructional prompts, AIP reveals how trusted yet seemingly benign interface
components can be weaponized to degrade system integrity. The attack is crafted
to achieve three goals: (1) naturalness, to evade user detection; (2) utility,
to encourage use of prompts; and (3) robustness, to remain effective across
diverse query variations. We propose a diverse query generation strategy that
simulates realistic linguistic variation in user queries, enabling the
discovery of prompts that generalize across paraphrases and rephrasings.
Building on this, a genetic algorithm-based joint optimization is developed to
evolve adversarial prompts by balancing attack success, clean-task utility, and
stealthiness. Experimental results show that AIP achieves up to 95.23% ASR
while preserving benign functionality. These findings uncover a critical and
previously overlooked vulnerability in RAG systems, emphasizing the need to
reassess the shared instructional prompts.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†RAGç³»ç»Ÿä¸­çš„æ–°å‹æ”»å‡»æ–¹å¼Adversarial Instructional Prompt (AIP)ï¼Œé€šè¿‡æ“çºµå¹¿æ³›å¤ç”¨ä¸”æœªè¢«å®¡è®¡çš„æŒ‡ä»¤æç¤ºï¼ˆè€Œéç›´æ¥ç¯¡æ”¹ç”¨æˆ·æŸ¥è¯¢ï¼‰ï¼Œéšç§˜åœ°æ”¹å˜æ£€ç´¢è¡Œä¸ºä»¥æ“æ§è¾“å‡ºã€‚ç ”ç©¶æå‡ºåŸºäºç”Ÿæˆå¤šæ ·æŸ¥è¯¢å’Œé—ä¼ ç®—æ³•çš„è”åˆä¼˜åŒ–æ–¹æ³•ï¼Œæ­ç¤ºRAGä¸­åŸºäºæŒ‡ä»¤æç¤ºçš„å®‰å…¨æ¼æ´ï¼Œå®éªŒæ˜¾ç¤ºAIPæ”»å‡»æˆåŠŸç‡é«˜è¾¾95.23%ä¸”ä¿æŒæ­£å¸¸åŠŸèƒ½ï¼Œå¼ºè°ƒäº†é‡æ–°è¯„ä¼°å…±äº«æç¤ºé£é™©çš„å¿…è¦æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14956v1">Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems</a></td><td><details><summary>å±•å¼€</summary>This paper proposes a novel architectural framework aimed at enhancing
security and reliability in multi-agent systems (MAS). A central component of
this framework is a network of Sentinel Agents, functioning as a distributed
security layer that integrates techniques such as semantic analysis via large
language models (LLMs), behavioral analytics, retrieval-augmented verification,
and cross-agent anomaly detection. Such agents can potentially oversee
inter-agent communications, identify potential threats, enforce privacy and
access controls, and maintain comprehensive audit records. Complementary to the
idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator
Agent supervises policy implementation, and manages agent participation. In
addition, the Coordinator also ingests alerts from Sentinel Agents. Based on
these alerts, it can adapt policies, isolate or quarantine misbehaving agents,
and contain threats to maintain the integrity of the MAS ecosystem. This
dual-layered security approach, combining the continuous monitoring of Sentinel
Agents with the governance functions of Coordinator Agents, supports dynamic
and adaptive defense mechanisms against a range of threats, including prompt
injection, collusive agent behavior, hallucinations generated by LLMs, privacy
breaches, and coordinated multi-agent attacks. In addition to the architectural
design, we present a simulation study where 162 synthetic attacks of different
families (prompt injection, hallucination, and data exfiltration) were injected
into a multi-agent conversational environment. The Sentinel Agents successfully
detected the attack attempts, confirming the practical feasibility of the
proposed monitoring approach. The framework also offers enhanced system
observability, supports regulatory compliance, and enables policy evolution
over time.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å¢å¼ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰å®‰å…¨æ€§å’Œå¯é æ€§çš„æ–°å‹æ¶æ„æ¡†æ¶ï¼Œå…¶ä¸­åŒ…å«åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œè¯­ä¹‰åˆ†æã€æ£€ç´¢å¢å¼ºéªŒè¯ç­‰æŠ€æœ¯ã€‚Sentinel Agentsä½œä¸ºåˆ†å¸ƒå¼å®‰å…¨å±‚ç›‘æ§é€šä¿¡å¹¶è¯†åˆ«å¨èƒï¼ŒCoordinator Agentåˆ™å®æ–½ç­–ç•¥ç®¡ç†å’Œå¨èƒå“åº”ï¼Œå¹¶é€šè¿‡ä»¿çœŸéªŒè¯äº†è¯¥æ¡†æ¶å¯¹æŠ—å¤šç§æ”»å‡»ï¼ˆå¦‚æç¤ºæ³¨å…¥ã€å¹»è§‰ç”Ÿæˆï¼‰çš„æœ‰æ•ˆæ€§ã€‚å…¶æ£€ç´¢å¢å¼ºéªŒè¯ï¼ˆretrieval-augmented verificationï¼‰æŠ€æœ¯æ˜ç¡®ä½“ç°äº†RAGçš„åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14750v1">Enhancing Retrieval Augmentation via Adversarial Collaboration</a></td><td><details><summary>å±•å¼€</summary>Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºä¸€ç§åä¸ºAC-RAGçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥å¯¹æŠ—æ€§åä½œæœºåˆ¶ï¼ˆåŒ…å«é€šç”¨æ£€æµ‹å™¨å’Œé¢†åŸŸä¸“å®¶è§£æå™¨ä¸¤ä¸ªå¼‚æ„ä»£ç†ï¼‰ï¼Œæœ‰æ•ˆè§£å†³RAGä¸­å­˜åœ¨çš„"æ£€ç´¢å¹»è§‰"é—®é¢˜ï¼Œå³æ¨¡å‹æ— æ³•è¯†åˆ«ä½è´¨é‡æ£€ç´¢æ–‡æ¡£çš„ç¼ºé™·ã€‚å®éªŒè¡¨æ˜AC-RAGåœ¨æ£€ç´¢å‡†ç¡®æ€§å’Œå‚ç›´é¢†åŸŸæ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰å…ˆè¿›æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14623v1">Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language</a></td><td><details><summary>å±•å¼€</summary>Dynamic energy systems and controls require advanced modeling frameworks to
design and test supervisory and fault tolerant strategies. Modelica is a widely
used equation based language, but developing control modules is labor intensive
and requires specialized expertise. This paper examines the use of large
language models (LLMs) to automate the generation of Control Description
Language modules in the Building Modelica Library as a case study. We developed
a structured workflow that combines standardized prompt scaffolds, library
aware grounding, automated compilation with OpenModelica, and human in the loop
evaluation. Experiments were carried out on four basic logic tasks (And, Or,
Not, and Switch) and five control modules (chiller enable/disable, bypass valve
control, cooling tower fan speed, plant requests, and relief damper control).
The results showed that GPT 4o failed to produce executable Modelica code in
zero shot mode, while Claude Sonnet 4 achieved up to full success for basic
logic blocks with carefully engineered prompts. For control modules, success
rates reached 83 percent, and failed outputs required medium level human repair
(estimated one to eight hours). Retrieval augmented generation often produced
mismatches in module selection (for example, And retrieved as Or), while a
deterministic hard rule search strategy avoided these errors. Human evaluation
also outperformed AI evaluation, since current LLMs cannot assess simulation
results or validate behavioral correctness. Despite these limitations, the LLM
assisted workflow reduced the average development time from 10 to 20 hours down
to 4 to 6 hours per module, corresponding to 40 to 60 percent time savings.
These results highlight both the potential and current limitations of LLM
assisted Modelica generation, and point to future research in pre simulation
validation, stronger grounding, and closed loop evaluation.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è‡ªåŠ¨åŒ–ç”ŸæˆModelicaæ§åˆ¶æ¨¡å—çš„æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæ ‡å‡†åŒ–æç¤ºæ¡†æ¶ã€åº“æ„ŸçŸ¥åŸºç¡€ã€è‡ªåŠ¨ç¼–è¯‘å’Œäººå·¥è¯„ä¼°ï¼Œæ˜¾è‘—å‡å°‘äº†å¼€å‘æ—¶é—´ï¼ŒåŒæ—¶æŒ‡å‡ºäº†RAGåœ¨æ¨¡å—é€‰æ‹©ä¸Šçš„å±€é™æ€§ä»¥åŠæœªæ¥æ”¹è¿›æ–¹å‘ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14622v1">Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection</a></td><td><details><summary>å±•å¼€</summary>With the deployment of Large Language Models (LLMs) in interactive
applications, online malicious intent detection has become increasingly
critical. However, existing approaches fall short of handling diverse and
complex user queries in real time. To address these challenges, we introduce
ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework
for robust and efficient online malicious intent detection. In the training
stage, a high-capacity teacher model is trained on adversarially perturbed,
retrieval-augmented inputs to learn robust decision boundaries over diverse and
complex user queries. In the inference stage, a distillation scheduler
transfers the teacher's knowledge into a compact student model, with a
continually updated knowledge base collected online. At deployment, the compact
student model leverages top-K similar safety exemplars retrieved from the
online-updated knowledge base to enable both online and real-time malicious
query detection. Evaluations across ten safety benchmarks demonstrate that
ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's
performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on
out-of-distribution detection, while simultaneously delivering up to 5.6x lower
latency at 300 queries per second (QPS) in real-time applications.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ADRAGï¼ˆAdversarial Distilled Retrieval-Augmented Guardï¼‰ï¼Œä¸€ç§ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œå¯¹æŠ—è’¸é¦çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºå®æ—¶åœ¨çº¿æ¶æ„æ„å›¾æ£€æµ‹ã€‚é€šè¿‡è®­ç»ƒé˜¶æ®µåˆ©ç”¨æ£€ç´¢å¢å¼ºçš„å¯¹æŠ—æ‰°åŠ¨è¾“å…¥è®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µå°†çŸ¥è¯†è’¸é¦åˆ°è½»é‡çº§å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œå…¶åœ¨çº¿æ›´æ–°çš„çŸ¥è¯†åº“æ”¯æŒå®æ—¶æ£€ç´¢Top-Kç›¸ä¼¼å®‰å…¨ç¤ºä¾‹ï¼Œæ˜¾è‘—æå‡äº†æ¶æ„æŸ¥è¯¢æ£€æµ‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14608v1">Enterprise AI Must Enforce Participant-Aware Access Control</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) are increasingly deployed in enterprise settings
where they interact with multiple users and are trained or fine-tuned on
sensitive internal data. While fine-tuning enhances performance by
internalizing domain knowledge, it also introduces a critical security risk:
leakage of confidential training data to unauthorized users. These risks are
exacerbated when LLMs are combined with Retrieval-Augmented Generation (RAG)
pipelines that dynamically fetch contextual documents at inference time.
  We demonstrate data exfiltration attacks on AI assistants where adversaries
can exploit current fine-tuning and RAG architectures to leak sensitive
information by leveraging the lack of access control enforcement. We show that
existing defenses, including prompt sanitization, output filtering, system
isolation, and training-level privacy mechanisms, are fundamentally
probabilistic and fail to offer robust protection against such attacks.
  We take the position that only a deterministic and rigorous enforcement of
fine-grained access control during both fine-tuning and RAG-based inference can
reliably prevent the leakage of sensitive data to unauthorized recipients.
  We introduce a framework centered on the principle that any content used in
training, retrieval, or generation by an LLM is explicitly authorized for
\emph{all users involved in the interaction}. Our approach offers a simple yet
powerful paradigm shift for building secure multi-user LLM systems that are
grounded in classical access control but adapted to the unique challenges of
modern AI workflows. Our solution has been deployed in Microsoft Copilot
Tuning, a product offering that enables organizations to fine-tune models using
their own enterprise-specific data.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« æ¢è®¨äº†åœ¨ä¼ä¸šç¯å¢ƒä¸­éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“æ—¶é¢ä¸´çš„æ•°æ®å®‰å…¨é£é™©ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç»†ç²’åº¦è®¿é—®æ§åˆ¶çš„æ¡†æ¶ï¼Œä»¥é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ç»™æœªç»æˆæƒçš„ç”¨æˆ·ï¼Œå¹¶å·²åœ¨Microsoft Copilot Tuningä¸­éƒ¨ç½²åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14507v1">DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction</a></td><td><details><summary>å±•å¼€</summary>Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºDeKeyNLUæ•°æ®é›†å’ŒDeKeySQLç®¡é“ï¼Œé€šè¿‡æ”¹è¿›ä»»åŠ¡åˆ†è§£å’Œå…³é”®è¯æå–å¢å¼ºRAGåœ¨è‡ªç„¶è¯­è¨€è½¬SQLï¼ˆNL2SQLï¼‰ä¸­çš„æ€§èƒ½ï¼Œå®éªŒæ˜¾ç¤ºå…¶æ˜¾è‘—æå‡äº†BIRDå’ŒSpideræ•°æ®é›†ä¸Šçš„SQLç”Ÿæˆå‡†ç¡®ç‡ã€‚</details></td></tr></tbody></table>
