# ğŸ“š RAG Paper Daily

### ğŸ“… 2025-09-19
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.16112v1">CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion</a></td><td><details><summary>å±•å¼€</summary>Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºCodeRAGçš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ä»“åº“çº§ä»£ç è¡¥å…¨æ–¹æ³•ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚ä¸æ°å½“çš„æŸ¥è¯¢æ„å»ºã€å•ä¸€è·¯å¾„çš„ä»£ç æ£€ç´¢ä»¥åŠä»£ç æ£€ç´¢å™¨ä¸å¤§è¯­è¨€æ¨¡å‹ä¹‹é—´çš„ä¸å¯¹é½ã€‚CodeRAGé€šè¿‡æ¦‚ç‡å¼•å¯¼çš„æŸ¥è¯¢æ„å»ºã€å¤šè·¯å¾„ä»£ç æ£€ç´¢å’Œåå¥½å¯¹é½çš„BestFité‡æ’åºç­‰æ ¸å¿ƒç»„ä»¶ï¼Œæå‡äº†æ£€ç´¢å¢å¼ºçš„ä»“åº“çº§ä»£ç è¡¥å…¨çš„æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼ŒCodeRAGåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15883v1">RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning</a></td><td><details><summary>å±•å¼€</summary>Recent retrieval-augmented image captioning methods incorporate external
knowledge to compensate for the limitations in comprehending complex scenes.
However, current approaches face challenges in relation modeling: (1) the
representation of semantic prompts is too coarse-grained to capture
fine-grained relationships; (2) these methods lack explicit modeling of image
objects and their semantic relationships. To address these limitations, we
propose RACap, a relation-aware retrieval-augmented model for image captioning,
which not only mines structured relation semantics from retrieval captions, but
also identifies heterogeneous objects from the image. RACap effectively
retrieves structured relation features that contain heterogeneous visual
information to enhance the semantic consistency and relational expressiveness.
Experimental results show that RACap, with only 10.8M trainable parameters,
achieves superior performance compared to previous lightweight captioning
models.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºRACapçš„å…³ç³»æ„ŸçŸ¥æ£€ç´¢å¢å¼ºå›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡ä»æ£€ç´¢åˆ°çš„æè¿°ä¸­æŒ–æ˜ç»“æ„åŒ–å…³ç³»è¯­ä¹‰å¹¶è¯†åˆ«å›¾åƒä¸­çš„å¼‚æ„å¯¹è±¡ï¼Œä»¥æå‡è¯­ä¹‰ä¸€è‡´æ€§å’Œå…³ç³»è¡¨è¾¾èƒ½åŠ›ï¼Œå®éªŒæ˜¾ç¤ºå…¶åœ¨è½»é‡çº§æ¨¡å‹ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15577v1">Relevance to Utility: Process-Supervised Rewrite for RAG</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation systems often suffer from a gap between
optimizing retrieval relevance and generative utility: retrieved documents may
be topically relevant but still lack the content needed for effective reasoning
during generation. While existing "bridge" modules attempt to rewrite the
retrieved text for better generation, we show how they fail to capture true
document utility. In this work, we propose R2U, with a key distinction of
directly optimizing to maximize the probability of generating a correct answer
through process supervision. As such direct observation is expensive, we also
propose approximating an efficient distillation pipeline by scaling the
supervision from LLMs, which helps the smaller rewriter model generalize
better. We evaluate our method across multiple open-domain question-answering
benchmarks. The empirical results demonstrate consistent improvements over
strong bridging baselines.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºR2Uçš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³RAGç³»ç»Ÿä¸­æ£€ç´¢ç›¸å…³æ€§ä¸ç”Ÿæˆæ•ˆç”¨ä¹‹é—´çš„ä¸ä¸€è‡´é—®é¢˜ã€‚é€šè¿‡ç›´æ¥ä¼˜åŒ–ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡ï¼Œå¹¶åˆ©ç”¨LLMçš„ç›‘ç£ä¿¡å·æ¥é«˜æ•ˆè®­ç»ƒè¾ƒå°çš„é‡å†™æ¨¡å‹ï¼Œè®ºæ–‡åœ¨å¤šä¸ªå¼€æ”¾åŸŸé—®ç­”åŸºå‡†æµ‹è¯•ä¸­å±•ç¤ºäº†ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•çš„æ€§èƒ½ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-18
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.15211v1">What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques</a></td><td><details><summary>å±•å¼€</summary>Slide decks, serving as digital reports that bridge the gap between
presentation slides and written documents, are a prevalent medium for conveying
information in both academic and corporate settings. Their multimodal nature,
combining text, images, and charts, presents challenges for retrieval-augmented
generation systems, where the quality of retrieval directly impacts downstream
performance. Traditional approaches to slide retrieval often involve separate
indexing of modalities, which can increase complexity and lose contextual
information. This paper investigates various methodologies for effective slide
retrieval, including visual late-interaction embedding models like ColPali, the
use of visual rerankers, and hybrid retrieval techniques that combine dense
retrieval with BM25, further enhanced by textual rerankers and fusion methods
like Reciprocal Rank Fusion. A novel Vision-Language Models-based captioning
pipeline is also evaluated, demonstrating significantly reduced embedding
storage requirements compared to visual late-interaction techniques, alongside
comparable retrieval performance. Our analysis extends to the practical aspects
of these methods, evaluating their runtime performance and storage demands
alongside retrieval efficacy, thus offering practical guidance for the
selection and development of efficient and robust slide retrieval systems for
real-world applications.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¹»ç¯ç‰‡ï¼ˆåŒ…å«æ–‡æœ¬ã€å›¾åƒå’Œå›¾è¡¨ï¼‰çš„é«˜æ•ˆæ£€ç´¢æ–¹æ³•ï¼Œæ¢è®¨äº†è§†è§‰å»¶è¿Ÿäº¤äº’åµŒå…¥æ¨¡å‹ã€è§†è§‰é‡æ’åºå™¨ã€æ··åˆæ£€ç´¢æŠ€æœ¯ï¼ˆç»“åˆç¨ å¯†æ£€ç´¢ä¸BM25ï¼‰ç­‰æ–¹æ¡ˆï¼Œå¹¶æå‡ºåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„æ ‡é¢˜ç”Ÿæˆæµç¨‹ï¼Œåœ¨ä¿è¯æ£€ç´¢æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½å­˜å‚¨éœ€æ±‚ï¼Œä¸ºRAGç³»ç»Ÿä¸­å¹»ç¯ç‰‡æ£€ç´¢çš„å®é™…åº”ç”¨æä¾›æ•ˆèƒ½è¯„ä¼°ä¸å¼€å‘æŒ‡å¯¼ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.15159v1">AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
retrieving relevant documents from external sources to improve factual accuracy
and verifiability. However, this reliance introduces new attack surfaces within
the retrieval pipeline, beyond the LLM itself. While prior RAG attacks have
exposed such vulnerabilities, they largely rely on manipulating user queries,
which is often infeasible in practice due to fixed or protected user inputs.
This narrow focus overlooks a more realistic and stealthy vector: instructional
prompts, which are widely reused, publicly shared, and rarely audited. Their
implicit trust makes them a compelling target for adversaries to manipulate RAG
behavior covertly.
  We introduce a novel attack for Adversarial Instructional Prompt (AIP) that
exploits adversarial instructional prompts to manipulate RAG outputs by subtly
altering retrieval behavior. By shifting the attack surface to the
instructional prompts, AIP reveals how trusted yet seemingly benign interface
components can be weaponized to degrade system integrity. The attack is crafted
to achieve three goals: (1) naturalness, to evade user detection; (2) utility,
to encourage use of prompts; and (3) robustness, to remain effective across
diverse query variations. We propose a diverse query generation strategy that
simulates realistic linguistic variation in user queries, enabling the
discovery of prompts that generalize across paraphrases and rephrasings.
Building on this, a genetic algorithm-based joint optimization is developed to
evolve adversarial prompts by balancing attack success, clean-task utility, and
stealthiness. Experimental results show that AIP achieves up to 95.23% ASR
while preserving benign functionality. These findings uncover a critical and
previously overlooked vulnerability in RAG systems, emphasizing the need to
reassess the shared instructional prompts.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†RAGç³»ç»Ÿä¸­çš„æ–°å‹æ”»å‡»æ–¹å¼Adversarial Instructional Prompt (AIP)ï¼Œé€šè¿‡æ“çºµå¹¿æ³›å¤ç”¨ä¸”æœªè¢«å®¡è®¡çš„æŒ‡ä»¤æç¤ºï¼ˆè€Œéç›´æ¥ç¯¡æ”¹ç”¨æˆ·æŸ¥è¯¢ï¼‰ï¼Œéšç§˜åœ°æ”¹å˜æ£€ç´¢è¡Œä¸ºä»¥æ“æ§è¾“å‡ºã€‚ç ”ç©¶æå‡ºåŸºäºç”Ÿæˆå¤šæ ·æŸ¥è¯¢å’Œé—ä¼ ç®—æ³•çš„è”åˆä¼˜åŒ–æ–¹æ³•ï¼Œæ­ç¤ºRAGä¸­åŸºäºæŒ‡ä»¤æç¤ºçš„å®‰å…¨æ¼æ´ï¼Œå®éªŒæ˜¾ç¤ºAIPæ”»å‡»æˆåŠŸç‡é«˜è¾¾95.23%ä¸”ä¿æŒæ­£å¸¸åŠŸèƒ½ï¼Œå¼ºè°ƒäº†é‡æ–°è¯„ä¼°å…±äº«æç¤ºé£é™©çš„å¿…è¦æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14956v1">Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems</a></td><td><details><summary>å±•å¼€</summary>This paper proposes a novel architectural framework aimed at enhancing
security and reliability in multi-agent systems (MAS). A central component of
this framework is a network of Sentinel Agents, functioning as a distributed
security layer that integrates techniques such as semantic analysis via large
language models (LLMs), behavioral analytics, retrieval-augmented verification,
and cross-agent anomaly detection. Such agents can potentially oversee
inter-agent communications, identify potential threats, enforce privacy and
access controls, and maintain comprehensive audit records. Complementary to the
idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator
Agent supervises policy implementation, and manages agent participation. In
addition, the Coordinator also ingests alerts from Sentinel Agents. Based on
these alerts, it can adapt policies, isolate or quarantine misbehaving agents,
and contain threats to maintain the integrity of the MAS ecosystem. This
dual-layered security approach, combining the continuous monitoring of Sentinel
Agents with the governance functions of Coordinator Agents, supports dynamic
and adaptive defense mechanisms against a range of threats, including prompt
injection, collusive agent behavior, hallucinations generated by LLMs, privacy
breaches, and coordinated multi-agent attacks. In addition to the architectural
design, we present a simulation study where 162 synthetic attacks of different
families (prompt injection, hallucination, and data exfiltration) were injected
into a multi-agent conversational environment. The Sentinel Agents successfully
detected the attack attempts, confirming the practical feasibility of the
proposed monitoring approach. The framework also offers enhanced system
observability, supports regulatory compliance, and enables policy evolution
over time.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å¢å¼ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰å®‰å…¨æ€§å’Œå¯é æ€§çš„æ–°å‹æ¶æ„æ¡†æ¶ï¼Œå…¶ä¸­åŒ…å«åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œè¯­ä¹‰åˆ†æã€æ£€ç´¢å¢å¼ºéªŒè¯ç­‰æŠ€æœ¯ã€‚Sentinel Agentsä½œä¸ºåˆ†å¸ƒå¼å®‰å…¨å±‚ç›‘æ§é€šä¿¡å¹¶è¯†åˆ«å¨èƒï¼ŒCoordinator Agentåˆ™å®æ–½ç­–ç•¥ç®¡ç†å’Œå¨èƒå“åº”ï¼Œå¹¶é€šè¿‡ä»¿çœŸéªŒè¯äº†è¯¥æ¡†æ¶å¯¹æŠ—å¤šç§æ”»å‡»ï¼ˆå¦‚æç¤ºæ³¨å…¥ã€å¹»è§‰ç”Ÿæˆï¼‰çš„æœ‰æ•ˆæ€§ã€‚å…¶æ£€ç´¢å¢å¼ºéªŒè¯ï¼ˆretrieval-augmented verificationï¼‰æŠ€æœ¯æ˜ç¡®ä½“ç°äº†RAGçš„åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14750v1">Enhancing Retrieval Augmentation via Adversarial Collaboration</a></td><td><details><summary>å±•å¼€</summary>Retrieval-augmented Generation (RAG) is a prevalent approach for
domain-specific LLMs, yet it is often plagued by "Retrieval Hallucinations"--a
phenomenon where fine-tuned models fail to recognize and act upon poor-quality
retrieved documents, thus undermining performance. To address this, we propose
the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two
heterogeneous agents: a generalist Detector that identifies knowledge gaps, and
a domain-specialized Resolver that provides precise solutions. Guided by a
moderator, these agents engage in an adversarial collaboration, where the
Detector's persistent questioning challenges the Resolver's expertise. This
dynamic process allows for iterative problem dissection and refined knowledge
retrieval. Extensive experiments show that AC-RAG significantly improves
retrieval accuracy and outperforms state-of-the-art RAG methods across various
vertical domains.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºä¸€ç§åä¸ºAC-RAGçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥å¯¹æŠ—æ€§åä½œæœºåˆ¶ï¼ˆåŒ…å«é€šç”¨æ£€æµ‹å™¨å’Œé¢†åŸŸä¸“å®¶è§£æå™¨ä¸¤ä¸ªå¼‚æ„ä»£ç†ï¼‰ï¼Œæœ‰æ•ˆè§£å†³RAGä¸­å­˜åœ¨çš„"æ£€ç´¢å¹»è§‰"é—®é¢˜ï¼Œå³æ¨¡å‹æ— æ³•è¯†åˆ«ä½è´¨é‡æ£€ç´¢æ–‡æ¡£çš„ç¼ºé™·ã€‚å®éªŒè¡¨æ˜AC-RAGåœ¨æ£€ç´¢å‡†ç¡®æ€§å’Œå‚ç›´é¢†åŸŸæ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰å…ˆè¿›æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14623v1">Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language</a></td><td><details><summary>å±•å¼€</summary>Dynamic energy systems and controls require advanced modeling frameworks to
design and test supervisory and fault tolerant strategies. Modelica is a widely
used equation based language, but developing control modules is labor intensive
and requires specialized expertise. This paper examines the use of large
language models (LLMs) to automate the generation of Control Description
Language modules in the Building Modelica Library as a case study. We developed
a structured workflow that combines standardized prompt scaffolds, library
aware grounding, automated compilation with OpenModelica, and human in the loop
evaluation. Experiments were carried out on four basic logic tasks (And, Or,
Not, and Switch) and five control modules (chiller enable/disable, bypass valve
control, cooling tower fan speed, plant requests, and relief damper control).
The results showed that GPT 4o failed to produce executable Modelica code in
zero shot mode, while Claude Sonnet 4 achieved up to full success for basic
logic blocks with carefully engineered prompts. For control modules, success
rates reached 83 percent, and failed outputs required medium level human repair
(estimated one to eight hours). Retrieval augmented generation often produced
mismatches in module selection (for example, And retrieved as Or), while a
deterministic hard rule search strategy avoided these errors. Human evaluation
also outperformed AI evaluation, since current LLMs cannot assess simulation
results or validate behavioral correctness. Despite these limitations, the LLM
assisted workflow reduced the average development time from 10 to 20 hours down
to 4 to 6 hours per module, corresponding to 40 to 60 percent time savings.
These results highlight both the potential and current limitations of LLM
assisted Modelica generation, and point to future research in pre simulation
validation, stronger grounding, and closed loop evaluation.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯è‡ªåŠ¨åŒ–ç”ŸæˆModelicaæ§åˆ¶æ¨¡å—çš„æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆæ ‡å‡†åŒ–æç¤ºæ¡†æ¶ã€åº“æ„ŸçŸ¥åŸºç¡€ã€è‡ªåŠ¨ç¼–è¯‘å’Œäººå·¥è¯„ä¼°ï¼Œæ˜¾è‘—å‡å°‘äº†å¼€å‘æ—¶é—´ï¼ŒåŒæ—¶æŒ‡å‡ºäº†RAGåœ¨æ¨¡å—é€‰æ‹©ä¸Šçš„å±€é™æ€§ä»¥åŠæœªæ¥æ”¹è¿›æ–¹å‘ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14622v1">Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection</a></td><td><details><summary>å±•å¼€</summary>With the deployment of Large Language Models (LLMs) in interactive
applications, online malicious intent detection has become increasingly
critical. However, existing approaches fall short of handling diverse and
complex user queries in real time. To address these challenges, we introduce
ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework
for robust and efficient online malicious intent detection. In the training
stage, a high-capacity teacher model is trained on adversarially perturbed,
retrieval-augmented inputs to learn robust decision boundaries over diverse and
complex user queries. In the inference stage, a distillation scheduler
transfers the teacher's knowledge into a compact student model, with a
continually updated knowledge base collected online. At deployment, the compact
student model leverages top-K similar safety exemplars retrieved from the
online-updated knowledge base to enable both online and real-time malicious
query detection. Evaluations across ten safety benchmarks demonstrate that
ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's
performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on
out-of-distribution detection, while simultaneously delivering up to 5.6x lower
latency at 300 queries per second (QPS) in real-time applications.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†ADRAGï¼ˆAdversarial Distilled Retrieval-Augmented Guardï¼‰ï¼Œä¸€ç§ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œå¯¹æŠ—è’¸é¦çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºå®æ—¶åœ¨çº¿æ¶æ„æ„å›¾æ£€æµ‹ã€‚é€šè¿‡è®­ç»ƒé˜¶æ®µåˆ©ç”¨æ£€ç´¢å¢å¼ºçš„å¯¹æŠ—æ‰°åŠ¨è¾“å…¥è®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µå°†çŸ¥è¯†è’¸é¦åˆ°è½»é‡çº§å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œå…¶åœ¨çº¿æ›´æ–°çš„çŸ¥è¯†åº“æ”¯æŒå®æ—¶æ£€ç´¢Top-Kç›¸ä¼¼å®‰å…¨ç¤ºä¾‹ï¼Œæ˜¾è‘—æå‡äº†æ¶æ„æŸ¥è¯¢æ£€æµ‹çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14608v1">Enterprise AI Must Enforce Participant-Aware Access Control</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) are increasingly deployed in enterprise settings
where they interact with multiple users and are trained or fine-tuned on
sensitive internal data. While fine-tuning enhances performance by
internalizing domain knowledge, it also introduces a critical security risk:
leakage of confidential training data to unauthorized users. These risks are
exacerbated when LLMs are combined with Retrieval-Augmented Generation (RAG)
pipelines that dynamically fetch contextual documents at inference time.
  We demonstrate data exfiltration attacks on AI assistants where adversaries
can exploit current fine-tuning and RAG architectures to leak sensitive
information by leveraging the lack of access control enforcement. We show that
existing defenses, including prompt sanitization, output filtering, system
isolation, and training-level privacy mechanisms, are fundamentally
probabilistic and fail to offer robust protection against such attacks.
  We take the position that only a deterministic and rigorous enforcement of
fine-grained access control during both fine-tuning and RAG-based inference can
reliably prevent the leakage of sensitive data to unauthorized recipients.
  We introduce a framework centered on the principle that any content used in
training, retrieval, or generation by an LLM is explicitly authorized for
\emph{all users involved in the interaction}. Our approach offers a simple yet
powerful paradigm shift for building secure multi-user LLM systems that are
grounded in classical access control but adapted to the unique challenges of
modern AI workflows. Our solution has been deployed in Microsoft Copilot
Tuning, a product offering that enables organizations to fine-tune models using
their own enterprise-specific data.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡æ–‡ç« æ¢è®¨äº†åœ¨ä¼ä¸šç¯å¢ƒä¸­éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“æ—¶é¢ä¸´çš„æ•°æ®å®‰å…¨é£é™©ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç»†ç²’åº¦è®¿é—®æ§åˆ¶çš„æ¡†æ¶ï¼Œä»¥é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ç»™æœªç»æˆæƒçš„ç”¨æˆ·ï¼Œå¹¶å·²åœ¨Microsoft Copilot Tuningä¸­éƒ¨ç½²åº”ç”¨ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14507v1">DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction</a></td><td><details><summary>å±•å¼€</summary>Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that
simplifies database access for non-technical users by converting natural
language queries into SQL commands. Recent advancements, particularly those
integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT)
reasoning, have made significant strides in enhancing NL2SQL performance.
However, challenges such as inaccurate task decomposition and keyword
extraction by LLMs remain major bottlenecks, often leading to errors in SQL
generation. While existing datasets aim to mitigate these issues by fine-tuning
models, they struggle with over-fragmentation of tasks and lack of
domain-specific keyword annotations, limiting their effectiveness. To address
these limitations, we present DeKeyNLU, a novel dataset which contains 1,500
meticulously annotated QA pairs aimed at refining task decomposition and
enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with
DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three
distinct modules for user question understanding, entity retrieval, and
generation to improve SQL generation accuracy. We benchmarked multiple model
configurations within DeKeySQL RAG pipeline. Experimental results demonstrate
that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy
on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºDeKeyNLUæ•°æ®é›†å’ŒDeKeySQLç®¡é“ï¼Œé€šè¿‡æ”¹è¿›ä»»åŠ¡åˆ†è§£å’Œå…³é”®è¯æå–å¢å¼ºRAGåœ¨è‡ªç„¶è¯­è¨€è½¬SQLï¼ˆNL2SQLï¼‰ä¸­çš„æ€§èƒ½ï¼Œå®éªŒæ˜¾ç¤ºå…¶æ˜¾è‘—æå‡äº†BIRDå’ŒSpideræ•°æ®é›†ä¸Šçš„SQLç”Ÿæˆå‡†ç¡®ç‡ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-17
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.14436v1">When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine</a></td><td><details><summary>å±•å¼€</summary>Generative search engines (GEs) leverage large language models (LLMs) to
deliver AI-generated summaries with website citations, establishing novel
traffic acquisition channels while fundamentally altering the search engine
optimization landscape. To investigate the distinctive characteristics of GEs,
we collect data through interactions with Google's generative and conventional
search platforms, compiling a dataset of approximately ten thousand websites
across both channels. Our empirical analysis reveals that GEs exhibit
preferences for citing content characterized by significantly higher
predictability for underlying LLMs and greater semantic similarity among
selected sources. Through controlled experiments utilizing retrieval augmented
generation (RAG) APIs, we demonstrate that these citation preferences emerge
from intrinsic LLM tendencies to favor content aligned with their generative
expression patterns. Motivated by applications of LLMs to optimize website
content, we conduct additional experimentation to explore how LLM-based content
polishing by website proprietors alters AI summaries, finding that such
polishing paradoxically enhances information diversity within AI summaries.
Finally, to assess the user-end impact of LLM-induced information increases, we
design a generative search engine and recruit Prolific participants to conduct
a randomized controlled experiment involving an information-seeking and writing
task. We find that higher-educated users exhibit minimal changes in their final
outputs' information diversity but demonstrate significantly reduced task
completion time when original sites undergo polishing. Conversely,
lower-educated users primarily benefit through enhanced information density in
their task outputs while maintaining similar completion times across
experimental groups.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡ç ”ç©¶ç”Ÿæˆå¼æœç´¢å¼•æ“ï¼ˆGEsï¼‰çš„ç‰¹ç‚¹åŠå…¶å¼•ç”¨åå¥½ï¼Œå‘ç°GEså€¾å‘äºå¼•ç”¨ä¸åº•å±‚LLMç”Ÿæˆè¡¨è¾¾æ¨¡å¼ä¸€è‡´çš„å†…å®¹ï¼Œå¹¶é€šè¿‡RAG APIå®éªŒéªŒè¯äº†è¿™ä¸€åå¥½æºè‡ªLLMçš„å†…åœ¨å€¾å‘ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢è®¨äº†ç½‘ç«™æ‰€æœ‰è€…é€šè¿‡LLMä¼˜åŒ–å†…å®¹å¯¹AIæ‘˜è¦çš„å½±å“ï¼Œå¹¶è¯„ä¼°äº†ä¸åŒæ•™è‚²èƒŒæ™¯ç”¨æˆ·åœ¨ä½¿ç”¨GEsæ—¶çš„è¡¨ç°å·®å¼‚ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14435v1">Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) have transformed natural language processing
(NLP), enabling diverse applications by integrating large-scale pre-trained
knowledge. However, their static knowledge limits dynamic reasoning over
external information, especially in knowledge-intensive domains.
Retrieval-Augmented Generation (RAG) addresses this challenge by combining
retrieval mechanisms with generative modeling to improve contextual
understanding. Traditional RAG systems suffer from disrupted contextual
integrity due to text chunking and over-reliance on semantic similarity for
retrieval, often resulting in shallow and less accurate responses. We propose
Causal-Counterfactual RAG, a novel framework that integrates explicit causal
graphs representing cause-effect relationships into the retrieval process and
incorporates counterfactual reasoning grounded on the causal structure. Unlike
conventional methods, our framework evaluates not only direct causal evidence
but also the counterfactuality of associated causes, combining results from
both to generate more robust, accurate, and interpretable answers. By
leveraging causal pathways and associated hypothetical scenarios,
Causal-Counterfactual RAG preserves contextual coherence, reduces
hallucination, and enhances reasoning fidelity.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºCausal-Counterfactual RAGçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡å°†æ˜¾å¼å› æœå›¾æ•´åˆåˆ°æ£€ç´¢è¿‡ç¨‹ä¸­å¹¶å¼•å…¥åŸºäºå› æœç»“æ„çš„åäº‹å®æ¨ç†ï¼Œè§£å†³äº†ä¼ ç»ŸRAGç³»ç»Ÿå› æ–‡æœ¬åˆ†å—å’Œè¿‡åº¦ä¾èµ–è¯­ä¹‰ç›¸ä¼¼æ€§è€Œå¯¼è‡´çš„ä¸Šä¸‹æ–‡ä¸è¿è´¯å’Œå›ç­”æµ…æ˜¾çš„é—®é¢˜ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€é²æ£’ä¸”å¯è§£é‡Šçš„ç­”æ¡ˆã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13978v1">LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology</a></td><td><details><summary>å±•å¼€</summary>Modern scientific discovery increasingly relies on workflows that process
data across the Edge, Cloud, and High Performance Computing (HPC) continuum.
Comprehensive and in-depth analyses of these data are critical for hypothesis
validation, anomaly detection, reproducibility, and impactful findings.
Although workflow provenance techniques support such analyses, at large scale,
the provenance data become complex and difficult to analyze. Existing systems
depend on custom scripts, structured queries, or static dashboards, limiting
data interaction. In this work, we introduce an evaluation methodology,
reference architecture, and open-source implementation that leverages
interactive Large Language Model (LLM) agents for runtime data analysis. Our
approach uses a lightweight, metadata-driven design that translates natural
language into structured provenance queries. Evaluations across LLaMA, GPT,
Gemini, and Claude, covering diverse query classes and a real-world chemistry
workflow, show that modular design, prompt tuning, and Retrieval-Augmented
Generation (RAG) enable accurate and insightful LLM agent responses beyond
recorded provenance.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨äº¤äº’å¼å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†è¿›è¡Œè¿è¡Œæ—¶æ•°æ®åˆ†æçš„æ–¹æ³•ï¼Œé‡‡ç”¨è½»é‡çº§ã€ä»¥å…ƒæ•°æ®é©±åŠ¨çš„è®¾è®¡å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºç»“æ„åŒ–çš„æº¯æºæŸ¥è¯¢ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å®éªŒï¼ˆæ¶µç›–å¤šç§LLMæ¨¡å‹åŠå®é™…åŒ–å­¦å·¥ä½œæµï¼‰è¯æ˜ï¼Œå…¶æ¨¡å—åŒ–è®¾è®¡ã€æç¤ºè°ƒä¼˜åŠæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯èƒ½æ˜¾è‘—æå‡LLMä»£ç†å“åº”çš„å‡†ç¡®æ€§å’Œæ´å¯ŸåŠ›ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿè®°å½•çš„æº¯æºæ•°æ®èƒ½åŠ›ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13930v1">Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG</a></td><td><details><summary>å±•å¼€</summary>Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡ç ”ç©¶å¤šè¯­è¨€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆmRAGï¼‰ç³»ç»Ÿä¸­è¯­è¨€åå¥½å¯¹ç”Ÿæˆå’Œå¼•ç”¨çš„å½±å“ï¼Œå‘ç°æ¨¡å‹å€¾å‘äºå¼•ç”¨è‹±æ–‡æ¥æºï¼Œä¸”å¯èƒ½ç‰ºç‰²æ–‡æ¡£ç›¸å…³æ€§è€Œé€‰æ‹©è¯­è¨€åå¥½ï¼Œæ­ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€è¯­å¢ƒä¸­çš„å¼•ç”¨è¡Œä¸ºç‰¹ç‚¹ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13772v1">Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) integrates external knowledge into large
language models to improve response quality. However, recent work has shown
that RAG systems are highly vulnerable to poisoning attacks, where malicious
texts are inserted into the knowledge database to influence model outputs.
While several defenses have been proposed, they are often circumvented by more
adaptive or sophisticated attacks.
  This paper presents RAGOrigin, a black-box responsibility attribution
framework designed to identify which texts in the knowledge database are
responsible for misleading or incorrect generations. Our method constructs a
focused attribution scope tailored to each misgeneration event and assigns a
responsibility score to each candidate text by evaluating its retrieval
ranking, semantic relevance, and influence on the generated response. The
system then isolates poisoned texts using an unsupervised clustering method. We
evaluate RAGOrigin across seven datasets and fifteen poisoning attacks,
including newly developed adaptive poisoning strategies and multi-attacker
scenarios. Our approach outperforms existing baselines in identifying poisoned
content and remains robust under dynamic and noisy conditions. These results
suggest that RAGOrigin provides a practical and effective solution for tracing
the origins of corrupted knowledge in RAG systems.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºRAGOriginæ¡†æ¶ï¼Œé’ˆå¯¹RAGç³»ç»Ÿä¸­çŸ¥è¯†åº“ä¸­æ¯’æ”»å‡»å¯¼è‡´é”™è¯¯ç”Ÿæˆçš„é—®é¢˜ï¼Œé€šè¿‡é»‘ç›’è´£ä»»æº¯æºæ–¹æ³•åˆ†ææ£€ç´¢æ’åºã€è¯­ä¹‰ç›¸å…³æ€§å’Œç”Ÿæˆå“åº”å½±å“ï¼Œè¯†åˆ«å’Œéš”ç¦»æ¶æ„æ–‡æœ¬ï¼Œå¹¶åœ¨å¤šæ•°æ®é›†å’Œæ”»å‡»åœºæ™¯ä¸‹éªŒè¯å…¶ä¼˜äºç°æœ‰åŸºçº¿ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13702v1">DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models</a></td><td><details><summary>å±•å¼€</summary>Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDSCC-HSçš„æ–°å‹ä¸»åŠ¨å¼æ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€è‡ªæˆ‘å¼ºåŒ–æ ¡å‡†æ¥æŠ‘åˆ¶LLMçš„å¹»è§‰é—®é¢˜ï¼Œé‡‡ç”¨åŒä»£ç†æ¨¡å‹ï¼ˆFAPå’ŒHDPï¼‰åœ¨è‡ªå›å½’è§£ç è¿‡ç¨‹ä¸­å®æ—¶ä¿®æ­£ç›®æ ‡æ¨¡å‹çš„è¾“å‡ºã€‚å°½ç®¡å±äºRAGç›¸å…³ç ”ç©¶ï¼ˆæåˆ°RAGä½œä¸ºç°æœ‰æ–¹æ³•å¯¹æ¯”ï¼‰ï¼Œä½†å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åœ¨äºä¸ä¾èµ–å¤–éƒ¨æ£€ç´¢çš„ä¸»åŠ¨å¹²é¢„æœºåˆ¶ï¼Œå®éªŒè¯æ˜åœ¨TruthfulQAå’ŒBioGENåŸºå‡†ä¸­æ˜¾è‘—æå‡äº†ç”Ÿæˆå†…å®¹çš„çœŸå®æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13683v1">Improving Context Fidelity via Native Retrieval-Augmented Reasoning</a></td><td><details><summary>å±•å¼€</summary>Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†CAREæ¡†æ¶ï¼Œé€šè¿‡è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ˜¾å¼æ•´åˆä¸Šä¸‹æ–‡è¯æ®å¹¶ç»“åˆè‡ªèº«æ£€ç´¢èƒ½åŠ›ï¼Œæ”¹è¿›äº†ä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢å‡†ç¡®æ€§å’Œç­”æ¡ˆç”Ÿæˆæ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šé¡¹QAåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç›‘ç£å¾®è°ƒå’Œå¤–éƒ¨æ£€ç´¢æ–¹æ¡ˆï¼Œå¢å¼ºäº†LLMsåœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.13626v1">Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval</a></td><td><details><summary>å±•å¼€</summary>Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºAIçš„æ¡†æ¶ï¼Œé€šè¿‡è¯†åˆ«æœªå……åˆ†è¦†ç›–çš„ä¸»é¢˜ï¼ˆç¼ºå£ï¼‰æ¥å¢å¼ºè¯­æ–™åº“ï¼Œå¹¶è¯„ä¼°äº†å…¶åœ¨å››ç§æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“ä¸­çš„æ•ˆæœï¼Œç»“æœæ˜¾ç¤ºå®šå‘å¢å¼ºèƒ½ä»¥è¾ƒå°çš„æ‰©å±•è¾¾åˆ°æ¥è¿‘æœ€ä¼˜çš„æ£€ç´¢æ€§èƒ½ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-16
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.12765v1">InfoGain-RAG: Boosting Retrieval-Augmented Generation via Document Information Gain-based Reranking and Filtering</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
address key limitations of Large Language Models (LLMs), such as hallucination,
outdated knowledge, and lacking reference. However, current RAG frameworks
often struggle with identifying whether retrieved documents meaningfully
contribute to answer generation. This shortcoming makes it difficult to filter
out irrelevant or even misleading content, which notably impacts the final
performance. In this paper, we propose Document Information Gain (DIG), a novel
metric designed to quantify the contribution of retrieved documents to correct
answer generation. DIG measures a document's value by computing the difference
of LLM's generation confidence with and without the document augmented.
Further, we introduce InfoGain-RAG, a framework that leverages DIG scores to
train a specialized reranker, which prioritizes each retrieved document from
exact distinguishing and accurate sorting perspectives. This approach can
effectively filter out irrelevant documents and select the most valuable ones
for better answer generation. Extensive experiments across various models and
benchmarks demonstrate that InfoGain-RAG can significantly outperform existing
approaches, on both single and multiple retrievers paradigm. Specifically on
NaturalQA, it achieves the improvements of 17.9%, 4.5%, 12.5% in exact match
accuracy against naive RAG, self-reflective RAG and modern ranking-based RAG
respectively, and even an average of 15.3% increment on advanced proprietary
model GPT-4o across all datasets. These results demonstrate the feasibility of
InfoGain-RAG as it can offer a reliable solution for RAG in multiple
applications.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œæ–‡æ¡£ä¿¡æ¯å¢ç›Šï¼ˆDIGï¼‰â€çš„æ–°æŒ‡æ ‡ï¼Œç”¨äºé‡åŒ–æ£€ç´¢åˆ°çš„æ–‡æ¡£å¯¹ç”Ÿæˆæ­£ç¡®ç­”æ¡ˆçš„è´¡çŒ®ï¼Œå¹¶è¿›ä¸€æ­¥ä»‹ç»äº†åŸºäºDIGçš„InfoGain-RAGæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡è®­ç»ƒä¸“é—¨çš„é‡æ–°æ’åºæ¨¡å‹æ¥ä¼˜å…ˆé€‰æ‹©æœ€æœ‰ä»·å€¼çš„æ–‡æ¡£ï¼Œæ˜¾è‘—æå‡äº†RAGçš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12743v1">Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs</a></td><td><details><summary>å±•å¼€</summary>We propose a new, training-free method, Graph Reasoning via Retrieval
Augmented Framework (GRRAF), that harnesses retrieval-augmented generation
(RAG) alongside the code-generation capabilities of large language models
(LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target
graph is stored in a graph database, and the LLM is prompted to generate
executable code queries that retrieve the necessary information. This approach
circumvents the limitations of existing methods that require extensive
finetuning or depend on predefined algorithms, and it incorporates an error
feedback loop with a time-out mechanism to ensure both correctness and
efficiency. Experimental evaluations on the GraphInstruct dataset reveal that
GRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle
detection, bipartite graph checks, shortest path computation, and maximum flow,
while maintaining consistent token costs regardless of graph sizes. Imperfect
but still very high performance is observed on subgraph matching. Notably,
GRRAF scales effectively to large graphs with up to 10,000 nodes.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºGRRAFçš„æ–°å‹å…è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä»£ç ç”Ÿæˆèƒ½åŠ›æ¥è§£å†³å¹¿æ³›çš„å›¾æ¨ç†ä»»åŠ¡ã€‚GRRAFé€šè¿‡å°†ç›®æ ‡å›¾å­˜å‚¨åœ¨å›¾å½¢æ•°æ®åº“ä¸­ï¼Œå¹¶æç¤ºLLMç”Ÿæˆå¯æ‰§è¡Œçš„ä»£ç æŸ¥è¯¢æ¥æ£€ç´¢å¿…è¦ä¿¡æ¯ï¼Œä»è€Œé¿å…äº†ç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡å¾®è°ƒæˆ–ä¾èµ–é¢„å®šä¹‰ç®—æ³•çš„é™åˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGRRAFåœ¨å¤§å¤šæ•°å›¾æ¨ç†ä»»åŠ¡ä¸Šå®ç°äº†100%çš„å‡†ç¡®ç‡ï¼Œå¹¶èƒ½æœ‰æ•ˆæ‰©å±•åˆ°åŒ…å«å¤šè¾¾10,000ä¸ªèŠ‚ç‚¹çš„å¤§å‹å›¾ä¸­ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12653v1">Beyond Artificial Misalignment: Detecting and Grounding Semantic-Coordinated Multimodal Manipulations</a></td><td><details><summary>å±•å¼€</summary>The detection and grounding of manipulated content in multimodal data has
emerged as a critical challenge in media forensics. While existing benchmarks
demonstrate technical progress, they suffer from misalignment artifacts that
poorly reflect real-world manipulation patterns: practical attacks typically
maintain semantic consistency across modalities, whereas current datasets
artificially disrupt cross-modal alignment, creating easily detectable
anomalies. To bridge this gap, we pioneer the detection of
semantically-coordinated manipulations where visual edits are systematically
paired with semantically consistent textual descriptions. Our approach begins
with constructing the first Semantic-Aligned Multimodal Manipulation (SAMM)
dataset, generated through a two-stage pipeline: 1) applying state-of-the-art
image manipulations, followed by 2) generation of contextually-plausible
textual narratives that reinforce the visual deception. Building on this
foundation, we propose a Retrieval-Augmented Manipulation Detection and
Grounding (RamDG) framework. RamDG commences by harnessing external knowledge
repositories to retrieve contextual evidence, which serves as the auxiliary
texts and encoded together with the inputs through our image forgery grounding
and deep manipulation detection modules to trace all manipulations. Extensive
experiments demonstrate our framework significantly outperforms existing
methods, achieving 2.06\% higher detection accuracy on SAMM compared to
state-of-the-art approaches. The dataset and code are publicly available at
https://github.com/shen8424/SAMM-RamDG-CAP.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºRAMDGçš„æ£€ç´¢å¢å¼ºå¤šæ¨¡æ€ç¯¡æ”¹æ£€æµ‹ä¸å®šä½æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºè¯­ä¹‰å¯¹é½çš„å¤šæ¨¡æ€ç¯¡æ”¹æ•°æ®é›†ï¼ˆSAMMï¼‰å¹¶åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢è¾…åŠ©è¯æ®ï¼Œæ˜¾è‘—æå‡äº†ç¯¡æ”¹æ£€æµ‹çš„å‡†ç¡®ç‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12589v1">Redefining CX with Agentic AI: Minerva CQ Case Study</a></td><td><details><summary>å±•å¼€</summary>Despite advances in AI for contact centers, customer experience (CX)
continues to suffer from high average handling time (AHT), low first-call
resolution, and poor customer satisfaction (CSAT). A key driver is the
cognitive load on agents, who must navigate fragmented systems, troubleshoot
manually, and frequently place customers on hold. Existing AI-powered
agent-assist tools are often reactive driven by static rules, simple prompting,
or retrieval-augmented generation (RAG) without deeper contextual reasoning. We
introduce Agentic AI goal-driven, autonomous, tool-using systems that
proactively support agents in real time. Unlike conventional approaches,
Agentic AI identifies customer intent, triggers modular workflows, maintains
evolving context, and adapts dynamically to conversation state. This paper
presents a case study of Minerva CQ, a real-time Agent Assist product deployed
in voice-based customer support. Minerva CQ integrates real-time transcription,
intent and sentiment detection, entity recognition, contextual retrieval,
dynamic customer profiling, and partial conversational summaries enabling
proactive workflows and continuous context-building. Deployed in live
production, Minerva CQ acts as an AI co-pilot, delivering measurable
improvements in agent efficiency and customer experience across multiple
deployments.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†Agentic AIåœ¨å®¢æœä¸­å¿ƒçš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯Minerva CQäº§å“ï¼Œå®ƒç»“åˆäº†å®æ—¶è½¬å½•ã€æ„å›¾è¯†åˆ«å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰æŠ€æœ¯ï¼Œé€šè¿‡åŠ¨æ€ä¸Šä¸‹æ–‡å’Œå·¥ä½œæµæå‡å®¢æœä»£ç†æ•ˆç‡åŠå®¢æˆ·ä½“éªŒã€‚å°½ç®¡RAGæ˜¯ç°æœ‰æŠ€æœ¯ä¹‹ä¸€ï¼Œä½†æ–‡ç« é‡ç‚¹å¼ºè°ƒå…¶è¶…è¶Šä¼ ç»ŸRAGçš„è‡ªä¸»æ€§å’Œå®æ—¶æ€§èƒ½åŠ›ã€‚</details></td></tr></tbody></table>

### ğŸ“… 2025-09-15
<table style='width:100%;'><colgroup><col><col><col></colgroup><thead><tr><th>title</th><th>abstract</th><th>summary</th></tr></thead><tbody><tr><td><a href="http://arxiv.org/abs/2509.12382v1">LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation</a></td><td><details><summary>å±•å¼€</summary>The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†åœ¨æ¨èç³»ç»Ÿä¸­åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºè¯„ä¼°å·¥å…·çš„å¯è¡Œæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ³•å¾‹æ£€ç´¢ä¸ç”Ÿæˆï¼ˆRAGï¼‰é¢†åŸŸã€‚ç ”ç©¶é‡ç‚¹å…³æ³¨å¦‚ä½•é€‰æ‹©å¯ä¿¡çš„æŒ‡æ ‡ï¼ˆå¦‚Gwet's AC2å’Œç§©ç›¸å…³ç³»æ•°ï¼‰å’Œç»Ÿè®¡æ–¹æ³•ï¼ˆå¦‚Wilcoxon Signed-Rank Testï¼‰æ¥å¯¹é½LLMä¸äººç±»è¯„ä¼°ç»“æœï¼Œä»è€Œä¸ºé«˜é£é™©çš„RAGç³»ç»Ÿæä¾›å¯æ‰©å±•ä¸”ç²¾å‡†çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12168v1">RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing</a></td><td><details><summary>å±•å¼€</summary>Role-playing Large language models (LLMs) are increasingly deployed in
high-stakes domains such as healthcare, education, and governance, where
failures can directly impact user trust and well-being. A cost effective
paradigm for LLM role-playing is few-shot learning, but existing approaches
often cause models to break character in unexpected and potentially harmful
ways, especially when interacting with hostile users. Inspired by
Retrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a
text retrieval problem and propose a new prompting framework called
RAGs-to-Riches, which leverages curated reference demonstrations to condition
LLM responses. We evaluate our framework with LLM-as-a-judge preference voting
and introduce two novel token-level ROUGE metrics: Intersection over Output
(IOO) to quantity how much an LLM improvises and Intersection over References
(IOR) to measure few-shot demonstrations utilization rate during the evaluation
tasks. When simulating interactions with a hostile user, our prompting strategy
incorporates in its responses during inference an average of 35% more tokens
from the reference demonstrations. As a result, across 453 role-playing
interactions, our models are consistently judged as being more authentic, and
remain in-character more often than zero-shot and in-context Learning (ICL)
methods. Our method presents a scalable strategy for building robust,
human-aligned LLM role-playing frameworks.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºRAGs-to-Richesçš„æç¤ºæ¡†æ¶ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è§’è‰²æ‰®æ¼”é‡æ–°æ„å»ºä¸ºæ–‡æœ¬æ£€ç´¢é—®é¢˜ï¼Œé€šè¿‡åˆ©ç”¨ç²¾å¿ƒç­–åˆ’çš„å‚è€ƒæ¼”ç¤ºæ¥è°ƒèŠ‚LLMçš„å“åº”ã€‚è¯¥æ¡†æ¶åœ¨å¯¹æŠ—æ€§ç”¨æˆ·äº’åŠ¨ä¸­è¡¨ç°æ›´ä¼˜ï¼Œèƒ½æ›´æœ‰æ•ˆåœ°åˆ©ç”¨å‚è€ƒæ¼”ç¤ºï¼Œæé«˜è§’è‰²çš„çœŸå®æ€§å’Œä¸€è‡´æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12086v1">SAQ: Pushing the Limits of Vector Quantization through Code Adjustment and Dimension Segmentation</a></td><td><details><summary>å±•å¼€</summary>Approximate Nearest Neighbor Search (ANNS) plays a critical role in
applications such as search engines, recommender systems, and RAG for LLMs.
Vector quantization (VQ), a crucial technique for ANNS, is commonly used to
reduce space overhead and accelerate distance computations. However, despite
significant research advances, state-of-the-art VQ methods still face
challenges in balancing encoding efficiency and quantization accuracy. To
address these limitations, we propose a novel VQ method called SAQ. To improve
accuracy, SAQ employs a new dimension segmentation technique to strategically
partition PCA-projected vectors into segments along their dimensions. By
prioritizing leading dimension segments with larger magnitudes, SAQ allocates
more bits to high-impact segments, optimizing the use of the available space
quota. An efficient dynamic programming algorithm is developed to optimize
dimension segmentation and bit allocation, ensuring minimal quantization error.
To speed up vector encoding, SAQ devises a code adjustment technique to first
quantize each dimension independently and then progressively refine quantized
vectors using a coordinate-descent-like approach to avoid exhaustive
enumeration. Extensive experiments demonstrate SAQ's superiority over classical
methods (e.g., PQ, PCA) and recent state-of-the-art approaches (e.g., LVQ,
Extended RabitQ). SAQ achieves up to 80% reduction in quantization error and
accelerates encoding speed by over 80x compared to Extended RabitQ.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºSAQçš„æ–°å‹å‘é‡é‡åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨æ”¹è¿›è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼ˆANNSï¼‰ä¸­çš„ç¼–ç æ•ˆç‡å’Œé‡åŒ–ç²¾åº¦å¹³è¡¡é—®é¢˜ï¼Œé€šè¿‡ç»´åº¦åˆ†å‰²å’ŒåŠ¨æ€ç¼–ç¨‹ä¼˜åŒ–æŠ€æœ¯æ˜¾è‘—é™ä½é‡åŒ–è¯¯å·®å¹¶åŠ é€Ÿç¼–ç é€Ÿåº¦ï¼Œç›´æ¥å…³è”å¹¶ä¼˜åŒ–äº†RAGæŠ€æœ¯ä¸­æ£€ç´¢ç¯èŠ‚çš„æ ¸å¿ƒæ€§èƒ½ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.12042v1">FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval</a></td><td><details><summary>å±•å¼€</summary>Financial disclosures such as 10-K filings present challenging retrieval
problems due to their length, regulatory section hierarchy, and domain-specific
language, which standard retrieval-augmented generation (RAG) models underuse.
We introduce FinGEAR (Financial Mapping-Guided Enhanced Answer Retrieval), a
retrieval framework tailored to financial documents. FinGEAR combines a finance
lexicon for Item-level guidance (FLAM), dual hierarchical indices for
within-Item search (Summary Tree and Question Tree), and a two-stage
cross-encoder reranker. This design aligns retrieval with disclosure structure
and terminology, enabling fine-grained, query-aware context selection.
Evaluated on full 10-Ks with queries aligned to the FinQA dataset, FinGEAR
delivers consistent gains in precision, recall, F1, and relevancy, improving F1
by up to 56.7% over flat RAG, 12.5% over graph-based RAGs, and 217.6% over
prior tree-based systems, while also increasing downstream answer accuracy with
a fixed reader. By jointly modeling section hierarchy and domain lexicon
signals, FinGEAR improves retrieval fidelity and provides a practical
foundation for high-stakes financial analysis.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†FinGEARï¼Œä¸€ä¸ªé’ˆå¯¹é‡‘èæ–‡æ¡£ï¼ˆå¦‚10-Kæ–‡ä»¶ï¼‰ä¼˜åŒ–çš„æ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆé‡‘èè¯æ±‡è¡¨ï¼ˆFLAMï¼‰ã€åŒé‡å±‚æ¬¡ç´¢å¼•å’Œä¸¤é˜¶æ®µäº¤å‰ç¼–ç å™¨é‡æ’å™¨ï¼Œæ”¹è¿›äº†ä¼ ç»ŸRAGæ¨¡å‹åœ¨é‡‘èé¢†åŸŸçš„æ£€ç´¢æ•ˆæœï¼Œæ˜¾è‘—æå‡äº†ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œä¸‹æ¸¸ç­”æ¡ˆå‡†ç¡®æ€§ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11947v1">A GPU-Accelerated RAG-Based Telegram Assistant for Supporting Parallel Processing Students</a></td><td><details><summary>å±•å¼€</summary>This project addresses a critical pedagogical need: offering students
continuous, on-demand academic assistance beyond conventional reception hours.
I present a domain-specific Retrieval-Augmented Generation (RAG) system powered
by a quantized Mistral-7B Instruct model and deployed as a Telegram bot. The
assistant enhances learning by delivering real-time, personalized responses
aligned with the "Introduction to Parallel Processing" course materials. GPU
acceleration significantly improves inference latency, enabling practical
deployment on consumer hardware. This approach demonstrates how consumer GPUs
can enable affordable, private, and effective AI tutoring for HPC education.</details></td><td><details><summary>å±•å¼€</summary>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªé¢å‘æ•™è‚²é¢†åŸŸçš„RAGç³»ç»Ÿï¼ŒåŸºäºé‡åŒ–ç‰ˆMistral-7B Instructæ¨¡å‹æ„å»ºï¼Œé€šè¿‡Telegramæœºå™¨äººæä¾›å¹¶è¡Œå¤„ç†è¯¾ç¨‹çš„å®æ—¶ä¸ªæ€§åŒ–å­¦ä¹ æ”¯æŒï¼Œåˆ©ç”¨GPUåŠ é€Ÿå®ç°æ¶ˆè´¹çº§ç¡¬ä»¶éƒ¨ç½²ï¼Œå±•ç¤ºäº†ä½æˆæœ¬é«˜æ•ˆçš„AIè¾…å¯¼æ–¹æ¡ˆã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11937v1">MMORE: Massive Multimodal Open RAG & Extraction</a></td><td><details><summary>å±•å¼€</summary>We introduce MMORE, an open-source pipeline for Massive Multimodal Open
RetrievalAugmented Generation and Extraction, designed to ingest, transform,
and retrieve knowledge from heterogeneous document formats at scale. MMORE
supports more than fifteen file types, including text, tables, images, emails,
audio, and video, and processes them into a unified format to enable downstream
applications for LLMs. The architecture offers modular, distributed processing,
enabling scalable parallelization across CPUs and GPUs. On processing
benchmarks, MMORE demonstrates a 3.8-fold speedup over single-node baselines
and 40% higher accuracy than Docling on scanned PDFs. The pipeline integrates
hybrid dense-sparse retrieval and supports both interactive APIs and batch RAG
endpoints. Evaluated on PubMedQA, MMORE-augmented medical LLMs improve
biomedical QA accuracy with increasing retrieval depth. MMORE provides a
robust, extensible foundation for deploying task-agnostic RAG systems on
diverse, real-world multimodal data. The codebase is available at
https://github.com/swiss-ai/mmore.</details></td><td><details><summary>å±•å¼€</summary>MMOREæ˜¯ä¸€ä¸ªå¼€æºçš„å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿï¼Œæ”¯æŒå¤„ç†å¤šç§æ–‡æ¡£æ ¼å¼ï¼ˆå¦‚æ–‡æœ¬ã€è¡¨æ ¼ã€å›¾åƒç­‰ï¼‰ï¼Œå¹¶å°†å…¶ç»Ÿä¸€å¤„ç†ä»¥ä¾›å¤§è¯­è¨€æ¨¡å‹ä½¿ç”¨ã€‚è¯¥ç³»ç»Ÿé€šè¿‡åˆ†å¸ƒå¼å¤„ç†æé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œé›†æˆäº†æ··åˆæ£€ç´¢æ–¹æ³•ï¼Œå¹¶åœ¨åŒ»ç–—QAä»»åŠ¡ä¸­å±•ç°äº†æ€§èƒ½æå‡ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11687v1">A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection</a></td><td><details><summary>å±•å¼€</summary>As the Internet and social media evolve rapidly, distinguishing credible news
from a vast amount of complex information poses a significant challenge. Due to
the suddenness and instability of news events, the authenticity labels of news
can potentially shift as events develop, making it crucial for fake news
detection to obtain the latest event updates. Existing methods employ
retrieval-augmented generation to fill knowledge gaps, but they suffer from
issues such as insufficient credibility of retrieved content and interference
from noisy information. We propose a dynamic knowledge update-driven model for
fake news detection (DYNAMO), which leverages knowledge graphs to achieve
continuous updating of new knowledge and integrates with large language models
to fulfill dual functions: news authenticity detection and verification of new
knowledge correctness, solving the two key problems of ensuring the
authenticity of new knowledge and deeply mining news semantics. Specifically,
we first construct a news-domain-specific knowledge graph. Then, we use Monte
Carlo Tree Search to decompose complex news and verify them step by step.
Finally, we extract and update new knowledge from verified real news texts and
reasoning paths. Experimental results demonstrate that DYNAMO achieves the best
performance on two real-world datasets.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDYNAMOçš„å‡æ–°é—»æ£€æµ‹æ¨¡å‹ï¼Œé€šè¿‡ç»“åˆçŸ¥è¯†å›¾è°±çš„åŠ¨æ€æ›´æ–°ä¸å¤§è¯­è¨€æ¨¡å‹ï¼Œè§£å†³äº†ç°æœ‰æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•ä¸­æ£€ç´¢å†…å®¹å¯ä¿¡åº¦ä¸è¶³å’Œå™ªå£°å¹²æ‰°çš„é—®é¢˜ã€‚æ¨¡å‹åˆ©ç”¨æ–°é—»é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å›¾è°±ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢é€æ­¥åˆ†è§£å’ŒéªŒè¯å¤æ‚æ–°é—»ï¼ŒåŒæ—¶ä»å·²éªŒè¯çš„çœŸå®æ–°é—»ä¸­æå–å’Œæ›´æ–°çŸ¥è¯†ï¼Œå®ç°äº†æ–°é—»çœŸå®æ€§æ£€æµ‹ä¸æ–°çŸ¥è¯†æ­£ç¡®æ€§éªŒè¯çš„åŒé‡åŠŸèƒ½ã€‚å®éªŒç»“æœè¡¨æ˜DYNAMOåœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11645v1">Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework</a></td><td><details><summary>å±•å¼€</summary>This study presents the first comprehensive evaluation of Multimodal Large
Language Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS)
self-management. We constructed a database of approximately 3,000
anteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a
`Divide and Conquer' framework consisting of a visual question-answering task,
a domain knowledge assessment task, and a patient education counseling
assessment task. Our investigation revealed limitations of MLLMs' ability in
interpreting complex spinal radiographs and comprehending AIS care knowledge.
To address these, we pioneered enhancing MLLMs with spinal keypoint prompting
and compiled an AIS knowledge base for retrieval augmented generation (RAG),
respectively. Results showed varying effectiveness of visual prompting across
different architectures, while RAG substantially improved models' performances
on the knowledge assessment task. Our findings indicate current MLLMs are far
from capable in realizing personalized assistant in AIS care. The greatest
challenge lies in their abilities to obtain accurate detections of spinal
deformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).</details></td><td><details><summary>å±•å¼€</summary>è¯¥ç ”ç©¶è¯„ä¼°äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨é’å°‘å¹´ç‰¹å‘æ€§è„ŠæŸ±ä¾§å‡¸(AIS)è‡ªæˆ‘ç®¡ç†ä¸­çš„åº”ç”¨ï¼Œå‘ç°æ¨¡å‹åœ¨è§£è¯»å¤æ‚è„ŠæŸ±Xå…‰ç‰‡å’Œç†è§£AISæŠ¤ç†çŸ¥è¯†æ–¹é¢å­˜åœ¨å±€é™ï¼Œå¹¶é€šè¿‡å¼•å…¥è„ŠæŸ±å…³é”®ç‚¹æç¤ºå’Œæ„å»ºAISçŸ¥è¯†åº“ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯æ¥æå‡æ¨¡å‹æ€§èƒ½ï¼Œç»“æœæ˜¾ç¤ºRAGæ˜¾è‘—æ”¹å–„äº†æ¨¡å‹çš„çŸ¥è¯†è¯„ä¼°ä»»åŠ¡è¡¨ç°ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.14267v1">Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support</a></td><td><details><summary>å±•å¼€</summary>E-Commerce customer support requires quick and accurate answers grounded in
product data and past support cases. This paper develops a novel
retrieval-augmented generation (RAG) framework that uses knowledge graphs (KGs)
to improve the relevance of the answer and the factual grounding. We examine
recent advances in knowledge-augmented RAG and chatbots based on large language
models (LLM) in customer support, including Microsoft's GraphRAG and hybrid
retrieval architectures. We then propose a new answer synthesis algorithm that
combines structured subgraphs from a domain-specific KG with text documents
retrieved from support archives, producing more coherent and grounded
responses. We detail the architecture and knowledge flow of our system, provide
comprehensive experimental evaluation, and justify its design in real-time
support settings. Our implementation demonstrates 23\% improvement in factual
accuracy and 89\% user satisfaction in e-Commerce QA scenarios.</details></td><td><details><summary>å±•å¼€</summary>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºçŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰çš„RAGæ¡†æ¶ï¼Œæ—¨åœ¨æå‡ç”µå­å•†åŠ¡å®¢æœå›ç­”çš„ç›¸å…³æ€§å’Œäº‹å®ä¾æ®ï¼Œé€šè¿‡ç»“åˆç»“æ„åŒ–å­å›¾å’Œæ–‡æœ¬æ£€ç´¢ç”Ÿæˆæ›´è¿è´¯çš„å“åº”ï¼Œå®éªŒè¡¨æ˜å…¶å®ç°23%çš„äº‹å®å‡†ç¡®æ€§æå‡å’Œ89%çš„ç”¨æˆ·æ»¡æ„åº¦ã€‚</details></td></tr><tr><td><a href="http://arxiv.org/abs/2509.11552v2">HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking</a></td><td><details><summary>å±•å¼€</summary>Retrieval-Augmented Generation (RAG) enhances the response capabilities of
language models by integrating external knowledge sources. However, document
chunking as an important part of RAG system often lacks effective evaluation
tools. This paper first analyzes why existing RAG evaluation benchmarks are
inadequate for assessing document chunking quality, specifically due to
evidence sparsity. Based on this conclusion, we propose HiCBench, which
includes manually annotated multi-level document chunking points, synthesized
evidence-dense quetion answer(QA) pairs, and their corresponding evidence
sources. Additionally, we introduce the HiChunk framework, a multi-level
document structuring framework based on fine-tuned LLMs, combined with the
Auto-Merge retrieval algorithm to improve retrieval quality. Experiments
demonstrate that HiCBench effectively evaluates the impact of different
chunking methods across the entire RAG pipeline. Moreover, HiChunk achieves
better chunking quality within reasonable time consumption, thereby enhancing
the overall performance of RAG systems.</details></td><td><details><summary>å±•å¼€</summary>è¿™ç¯‡è®ºæ–‡èšç„¦äºRAGç³»ç»Ÿä¸­æ–‡æ¡£åˆ†å—ï¼ˆchunkingï¼‰è¯„ä¼°çš„ä¸è¶³ï¼Œæå‡ºå¸¦æœ‰æ‰‹åŠ¨æ ‡æ³¨å¤šçº§åˆ†å—ç‚¹çš„è¯„ä¼°åŸºå‡†HiCBenchå’Œè¯æ®å¯†é›†å‹QAæ•°æ®é›†ï¼ŒåŒæ—¶è®¾è®¡äº†åŸºäºå¾®è°ƒLLMsçš„å¤šçº§æ–‡æ¡£ç»“æ„åŒ–æ¡†æ¶HiChunkåŠAuto-Mergeæ£€ç´¢ç®—æ³•ï¼Œå®éªŒè¯æ˜å…¶èƒ½æœ‰æ•ˆæå‡åˆ†å—è´¨é‡å’ŒRAGæ•´ä½“æ€§èƒ½ã€‚</details></td></tr></tbody></table>
